import whisper
import os
import subprocess
import csv
import time
from pathlib import Path
from merge_segments import merge_short_segments

start_time = time.perf_counter()

# åŠ¨æ€å®šä½é¡¹ç›®æ ¹ç›®å½•
current_file = Path(__file__).resolve()
project_root = current_file.parents[1]  # ä½ è„šæœ¬åœ¨ preprocess/ï¼Œå¾€ä¸Šä¸¤çº§åˆ°é¡¹ç›®æ ¹

video_dir  = project_root / "data" / "raw"
clips_root = project_root / "data" / "clips"
audio_temp = "temp_audio.wav"

print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"è§†é¢‘è·¯å¾„: {video_dir}")
print(f"è¾“å‡ºè·¯å¾„: {clips_root}")

# === åŠ è½½ Whisper æ¨¡å‹ï¼ˆå¯ä»¥æ¢æˆ 'medium', 'large' ç­‰ï¼‰===
model = whisper.load_model("small")

# === éå†æ‰€æœ‰ mp4 è§†é¢‘ ===
for video_file in video_dir.glob("*.mp4"):
    print(f"\nğŸ“ æ­£åœ¨å¤„ç†ï¼š{video_file.name}")

    video_name = video_file.stem
    out_dir = clips_root / video_name
    video_out = out_dir / "video"
    audio_out = out_dir / "audio"
    label_path = out_dir / "label.csv"

    # åˆ›å»ºè¾“å‡ºç›®å½•
    video_out.mkdir(parents=True, exist_ok=True)
    audio_out.mkdir(parents=True, exist_ok=True)

    # Step 1: æå–æ•´æ®µéŸ³é¢‘
    subprocess.run([
        "ffmpeg", "-y", "-i", str(video_file),
        "-vn", "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1",
        "-af", "highpass=f=200,lowpass=f=3000",
        audio_temp
    ], check=True)

    # Step 2: Whisper è½¬å½•å¹¶åˆå¹¶ç‰‡æ®µ
    result   = model.transcribe(audio_temp)
    segments = merge_short_segments(result.get("segments", []),
                                    min_duration=2.0, max_gap=0.5)

    # Step 3: å†™å…¥ label.csv
    with open(label_path, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([
            "video_id", "clip_id", "text",
            "video_path", "audio_path",
            "label", "label_T", "label_A", "label_V",
            "annotation", "mode"
        ])

        # Step 4: åˆ‡åˆ†éŸ³è§†é¢‘ & å†™å…¥CSV
        for idx, seg in enumerate(segments, start=1):
            t0, t1 = seg["start"], seg["end"]
            text  = seg["text"].strip()

            video_path = video_out / f"{idx}.mp4"
            audio_path = audio_out / f"{idx}.wav"

            # åˆ‡è§†é¢‘
            subprocess.run([
                "ffmpeg", "-y", "-i", str(video_file),
                "-ss", str(t0), "-to", str(t1),
                "-c:v", "libx264", "-c:a", "aac",
                str(video_path)
            ], check=True)

            # åˆ‡éŸ³é¢‘
            subprocess.run([
                "ffmpeg", "-y", "-i", audio_temp,
                "-ss", str(t0), "-to", str(t1),
                "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1",
                str(audio_path)
            ], check=True)

            writer.writerow([
                video_name, idx, text,
                str(video_path.relative_to(out_dir)),
                str(audio_path.relative_to(out_dir)),
                "", "", "", "", "", "test"
            ])

            print(f"  âœ… {video_name} - ç‰‡æ®µ {idx} å®Œæˆ")

    # Step 5: åˆ é™¤ä¸´æ—¶éŸ³é¢‘
    os.remove(audio_temp)

print("\nğŸ‰ æ‰€æœ‰è§†é¢‘å¤„ç†å®Œæˆï¼")
print(f"è¿è¡Œæ—¶é—´: {time.perf_counter() - start_time:.2f} ç§’")